{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../static/data/dataset_3/IPL_Ball_by_Ball_2008_2022.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary features.\n",
    "# features_to_remove = ['fielders_involved', 'kind', 'player_out', 'isWicketDelivery', 'non_boundary', 'extras_run', 'batsman_run', 'extra_type']\n",
    "# data.drop(labels=features_to_remove, axis=1, inplace=True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename overs to over\n",
    "data = data.rename(columns={'overs': 'over'})\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overs(row):\n",
    "    over = str(row['over'])\n",
    "    ball = str(row['ballnumber'])\n",
    "    overs = over + '.' + ball if int(ball) < 6 else int(over) + 1\n",
    "    return float(overs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature overs in place of over and ballnumber\n",
    "data['overs'] = data.apply(overs, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do not need over and ballnumber features, drop them\n",
    "# data.drop(labels=['over', 'ballnumber'], axis=1, inplace=True)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature current_score\n",
    "data['current_score'] = data.groupby(['ID', 'innings'])['total_run'].cumsum()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature wickets\n",
    "data['wickets'] = data.groupby(['ID', 'innings'])['isWicketDelivery'].cumsum()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for calculating runs in last 5 overs\n",
    "def runs_rolling_sum_(df):\n",
    "    df['runs_in_prev_5'] = df['total_run'].rolling(window=30).sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature runs_in_prev_5\n",
    "\n",
    "# runs_in_prev_5 = data.groupby(['ID', 'innings'])['total_run'].rolling(window=30).sum()\n",
    "# runs_in_prev_5 = runs_in_prev_5.iloc[::-1]\n",
    "# runs_in_prev_5 = runs_in_prev_5.reset_index(drop=True)\n",
    "# data['runs_in_prev_5'] = runs_in_prev_5\n",
    "\n",
    "data = data.groupby(['ID', 'innings']).apply(runs_rolling_sum_)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for calculating wickets in last 5 overs\n",
    "def wickets_rolling_sum_(df):\n",
    "    df['wickets_in_prev_5'] = df['isWicketDelivery'].rolling(window=30).sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature wickets_in_prev_5\n",
    "\n",
    "# data['wickets_in_prev_5'] = data.groupby(['ID', 'innings'])['isWicketDelivery'].rolling(30).sum().reset_index(drop=True)\n",
    "# data = data.merge(data.groupby(['ID', 'innings'])['isWicketDelivery'].rolling(30).sum(), on=['ID', 'innings'])\n",
    "\n",
    "data = data.groupby(['ID', 'innings']).apply(wickets_rolling_sum_)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter the data based on 5 overs, we have to keep data of after 5 overs\n",
    "data = data[data['over'] >= 5]\n",
    "data.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since values of runs_in_prev_5 and wickets_in_prev_5 are in decimal, we have to make these values to integer\n",
    "def decimal_to_int_for_runs(row):\n",
    "    return int(row['runs_in_prev_5'])\n",
    "    \n",
    "def decimal_to_int_for_wickets(row):\n",
    "    return int(row['wickets_in_prev_5'])\n",
    "\n",
    "data['runs_in_prev_5'] = data.apply(decimal_to_int_for_runs, axis=1)\n",
    "data['wickets_in_prev_5'] = data.apply(decimal_to_int_for_wickets, axis=1)\n",
    "\n",
    "data.head(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total score of the innings\n",
    "total_score = data.groupby(['ID', 'innings']).sum()['total_run'].reset_index()\n",
    "total_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the total_run feature to total_score\n",
    "total_score = total_score.rename(columns={'total_run': 'total_score'})\n",
    "total_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature total_score\n",
    "data = data.merge(total_score[['ID', 'innings', 'total_score']], on=['ID', 'innings'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we do not need total_run feature, drop it\n",
    "# data.drop(labels=['total_run'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('../../static/data/dataset_3//IPL_Matches_2008_2022.csv')\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(matches[['ID', 'Team1', 'Team2']], on='ID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = data[data['Team2'] == data['BattingTeam']]['Team1'].index\n",
    "index2 = data[data['Team1'] == data['BattingTeam']]['Team2'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[index1, 'BowlingTeam'] = data.loc[index1, 'Team1']\n",
    "data.loc[index2, 'BowlingTeam'] = data.loc[index2, 'Team2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BattingTeam'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename old team names to new names\n",
    "data['BattingTeam'] = data['BattingTeam'].str.replace('Delhi Daredevils', 'Delhi Capitals')\n",
    "data['BattingTeam'] = data['BattingTeam'].str.replace('Kings XI Punjab', 'Punjab Kings')\n",
    "data['BattingTeam'] = data['BattingTeam'].str.replace('Deccan Chargers', 'Sunrisers Hyderabad')\n",
    "data['BattingTeam'] = data['BattingTeam'].str.replace('Rising Pune Supergiants', 'Rising Pune Supergiant')\n",
    "\n",
    "data['BowlingTeam'] = data['BowlingTeam'].str.replace('Delhi Daredevils', 'Delhi Capitals')\n",
    "data['BowlingTeam'] = data['BowlingTeam'].str.replace('Kings XI Punjab', 'Punjab Kings')\n",
    "data['BowlingTeam'] = data['BowlingTeam'].str.replace('Deccan Chargers', 'Sunrisers Hyderabad')\n",
    "data['BowlingTeam'] = data['BowlingTeam'].str.replace('Rising Pune Supergiants', 'Rising Pune Supergiant')\n",
    "\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current teams in IPl\n",
    "current_teams = [ 'Rajasthan Royals',\n",
    "    'Royal Challengers Bangalore',\n",
    "    'Sunrisers Hyderabad', \n",
    "    'Delhi Capitals', \n",
    "    'Chennai Super Kings',\n",
    "    'Gujarat Titans', \n",
    "    'Lucknow Super Giants', \n",
    "    'Kolkata Knight Riders',\n",
    "    'Punjab Kings', \n",
    "    'Mumbai Indians'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep data only of current teams in ipl\n",
    "data = data[data['BattingTeam'].isin(current_teams)]\n",
    "data = data[data['BowlingTeam'].isin(current_teams)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Features\n",
    "features_to_set = ['BattingTeam', 'BowlingTeam', 'overs', 'current_score', 'total_score', 'wickets', 'runs_in_prev_5', 'wickets_in_prev_5']\n",
    "final_data = data[features_to_set]\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('transformer', OneHotEncoder(sparse_output=False,drop='first'),['BattingTeam','BowlingTeam'])\n",
    "],\n",
    "remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_data.drop('total_score', axis=1)\n",
    "y = final_data['total_score']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('step1',transformer),\n",
    "    ('step2',RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_predictions = pipe.predict(X_test)\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_predictions)\n",
    "print('R^2 score: ', r2)\n",
    "sns.distplot(y_test - y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Mean Absolute Error\n",
    "print('MAE: ', metrics.mean_absolute_error(y_test , y_predictions))\n",
    "\n",
    "# Mean Squared Error\n",
    "print('MSE: ', metrics.mean_squared_error(y_test, y_predictions))\n",
    "\n",
    "# Root Mean Squared Error\n",
    "print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the IPL Score Predictor Model\n",
    "# import pickle\n",
    "# file_name = '../../static/models/ipl_score_predict_model.pkl'\n",
    "# pickle.dump(pipe , open(file_name,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
